{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code is the implementation of ROC Curve of Machine Learning Techniques: Logistic Regression, Decision Tree, Random Forest, Random Forest with Hyperparamters Tuning, SVM, and DNN methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import model_evaluation_utils as meu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Load and merge datasets # white = control; red = stroke; wine = data\n",
    "stroke_data = pd.read_csv('Injured Participants data.csv', delim_whitespace=False)\n",
    "control_data = pd.read_csv('Healthy Control Participants data.csv', delim_whitespace=False)\n",
    "\n",
    "# store wine type as an attribute\n",
    "stroke_data['data_type'] = 'stroke'   \n",
    "control_data['data_type'] = 'control'\n",
    "\n",
    "# merge control and stroke data\n",
    "datas = pd.concat([stroke_data, control_data])\n",
    "#datas = datas.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Prepare Training and Testing Datasets\n",
    "stp_features = datas.iloc[:,:-1]\n",
    "stp_feature_names = stp_features.columns\n",
    "stp_class_labels = np.array(datas['data_type'])\n",
    "\n",
    "X_data = datas.iloc[:,:-1]\n",
    "y_label = datas.iloc[:,-1]\n",
    "\n",
    "# Data Normalization\n",
    "ss = StandardScaler().fit(X_data)\n",
    "X = ss.transform(X_data)\n",
    "le = LabelEncoder()\n",
    "le.fit(y_label)\n",
    "y = le.transform(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots 10-fold with gold & GOLDERNROD\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "\n",
    "#from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#X, y = make_classification(n_samples=500, random_state=100, flip_y=0.3)\n",
    "\n",
    "#kf = KFold(n=len(y), n_folds=10)\n",
    "kf_lr = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "tprs_lr = []\n",
    "aucs_lr = []\n",
    "base_fpr_lr = np.linspace(0, 1, 101)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "#fig, ax = plt.subplots(1)\n",
    "\n",
    "for i, (train_lr, test_lr) in enumerate(kf_lr.split(X,y)):\n",
    "    model_lr = LogisticRegression().fit(X[train_lr], y[train_lr])\n",
    "    y_score_lr = model_lr.predict_proba(X[test_lr])\n",
    "    fpr_lr, tpr_lr, _ = roc_curve(y[test_lr], y_score_lr[:, 1])\n",
    "    auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "    #plt.plot(fpr_lr, tpr_lr, 'b', alpha=0.15) #label='LR (area = {:.2f})'.format(auc_lr))\n",
    "    plt.plot(fpr_lr, tpr_lr, lw=2, alpha=3, color='gold', label='ROC fold %d (AUC=%f)'%(i,auc_lr))\n",
    "    tpr_lr = interp(base_fpr_lr, fpr_lr, tpr_lr)\n",
    "    tpr_lr[0] = 0.0\n",
    "    tprs_lr.append(tpr_lr)\n",
    "    aucs_lr.append(auc_lr)\n",
    "    i=i+1\n",
    "\n",
    "tprs_lr = np.array(tprs_lr)\n",
    "mean_tprs_lr = tprs_lr.mean(axis=0)\n",
    "std_lr = tprs_lr.std(axis=0)\n",
    "\n",
    "tprs_upper_lr = np.minimum(mean_tprs_lr + std_lr, 1)\n",
    "tprs_lower_lr = mean_tprs_lr - std_lr\n",
    "\n",
    "plt.plot(base_fpr_lr, mean_tprs_lr, 'b')\n",
    "#plt.plot(base_fpr_lr, mean_tprs_lr)\n",
    "mean_auc_lr = auc(base_fpr_lr, mean_tprs_lr)\n",
    "#print('Auc: ', aucs_lr)\n",
    "#print('mean auc: %f' %mean_auc_lr)\n",
    "\n",
    "plt.plot(base_fpr_lr, mean_tprs_lr, color='goldenrod', label=r'Mean ROC (AUC=%f)'%(mean_auc_lr), lw=2, alpha=1)\n",
    "#plt.fill_between(base_fpr_lr, tprs_lower_lr, tprs_upper_lr, color='grey', alpha=0.3)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('LR ROC Curve')\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Green\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "kf_dt = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "tprs_dt = []\n",
    "aucs_dt = []\n",
    "base_fpr_dt = np.linspace(0, 1, 101)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "#fig, ax = plt.subplots(1)\n",
    "\n",
    "for i, (train_dt, test_dt) in enumerate(kf_dt.split(X,y)):\n",
    "    model_dt = DecisionTreeClassifier(max_depth=4).fit(X[train_dt], y[train_dt])\n",
    "    y_score_dt = model_dt.predict_proba(X[test_dt])\n",
    "    fpr_dt, tpr_dt, _ = roc_curve(y[test_dt], y_score_dt[:, 1])\n",
    "    auc_dt = auc(fpr_dt, tpr_dt)\n",
    "\n",
    "    #plt.plot(fpr_dt, tpr_dt, 'b', alpha=0.15) #label='LR (area = {:.2f})'.format(auc_lr))\n",
    "    plt.plot(fpr_dt, tpr_dt, lw=2, alpha=3, color='lightgreen', label='ROC fold %d (AUC=%f)'%(i,auc_dt))\n",
    "    tpr_dt = interp(base_fpr_dt, fpr_dt, tpr_dt)\n",
    "    tpr_dt[0] = 0.0\n",
    "    tprs_dt.append(tpr_dt)\n",
    "    aucs_dt.append(auc_dt)\n",
    "\n",
    "tprs_dt = np.array(tprs_dt)\n",
    "mean_tprs_dt = tprs_dt.mean(axis=0)\n",
    "std_dt = tprs_dt.std(axis=0)\n",
    "\n",
    "tprs_upper_dt = np.minimum(mean_tprs_dt + std_dt, 1)\n",
    "tprs_lower_dt = mean_tprs_dt - std_dt\n",
    "\n",
    "plt.plot(base_fpr_dt, mean_tprs_dt, 'b')\n",
    "mean_auc_dt = auc(base_fpr_dt, mean_tprs_dt)\n",
    "#print('Auc_dt: ', aucs_dt)\n",
    "#print('mean auc: %f' %mean_auc_dt)\n",
    "\n",
    "#plt.fill_between(base_fpr_dt, tprs_lower_dt, tprs_upper_dt, color='grey', alpha=0.3)\n",
    "plt.plot(base_fpr_dt, mean_tprs_dt, color='green', label=r'Mean ROC (AUC=%f)'%(mean_auc_dt), lw=2, alpha=1)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('DT ROC Curve')\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "\n",
    "# Hide the right and top spines\n",
    "#ax.spines['right'].set_visible(False)\n",
    "#ax.spines['top'].set_visible(False)\n",
    "# Only show ticks on the left and bottom spines\n",
    "#ax.yaxis.set_ticks_position('left')\n",
    "#ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# royalblue & blue\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "cv_rf = KFold(n_splits=10, shuffle=True) #random_state=42,\n",
    "\n",
    "tprs_rf = []\n",
    "aucs_rf = []\n",
    "base_fpr_rf = np.linspace(0, 1, 101)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "#fig, ax = plt.subplots(1)\n",
    "\n",
    "for i, (train_rf, test_rf) in enumerate(cv_rf.split(X,y)):\n",
    "    model_rf = RandomForestClassifier().fit(X[train_rf], y[train_rf])\n",
    "    y_score_rf = model_rf.predict_proba(X[test_rf])\n",
    "    fpr_rf, tpr_rf, _ = roc_curve(y[test_rf], y_score_rf[:, 1])\n",
    "    auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "    #plt.plot(fpr_rf, tpr_rf, 'b', alpha=0.15) #label='LR (area = {:.2f})'.format(auc_lr))\n",
    "    plt.plot(fpr_rf, tpr_rf, lw=2, alpha=3, color='royalblue', label='ROC fold %d (AUC=%f)'%(i,auc_rf))\n",
    "    tpr_rf = interp(base_fpr_rf, fpr_rf, tpr_rf)\n",
    "    tpr_rf[0] = 0.0\n",
    "    tprs_rf.append(tpr_rf)\n",
    "    aucs_rf.append(auc_rf)\n",
    "\n",
    "tprs_rf = np.array(tprs_rf)\n",
    "mean_tprs_rf = tprs_rf.mean(axis=0)\n",
    "std_rf = tprs_rf.std(axis=0)\n",
    "\n",
    "tprs_upper_rf = np.minimum(mean_tprs_rf + std_rf, 1)\n",
    "tprs_lower_rf = mean_tprs_rf - std_rf\n",
    "#print(tprs_upper_rf)\n",
    "#print(tprs_lower_rf)\n",
    "\n",
    "plt.plot(base_fpr_rf, mean_tprs_rf, 'b')\n",
    "mean_auc_rf = auc(base_fpr_rf, mean_tprs_rf)\n",
    "#print('Auc_rf: ', aucs_rf)\n",
    "#print('mean auc: %f' %mean_auc_rf)\n",
    "\n",
    "#plt.fill_between(base_fpr_rf, tprs_lower_rf, tprs_upper_rf) # , color='grey' , alpha=0.3\n",
    "plt.plot(base_fpr_rf, mean_tprs_rf, color='blue', label=r'Mean ROC (AUC=%f)'%(mean_auc_rf), lw=2, alpha=1)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('RF ROC Curve')\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aquamarine & turquoise\n",
    "# Random Forest with Hyperparameter Tuning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "cv_rft = KFold(n_splits=10, shuffle=True) # random_state=42\n",
    "\n",
    "tprs_rft = []\n",
    "aucs_rft = []\n",
    "base_fpr_rft = np.linspace(0, 1, 101)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "#fig, ax = plt.subplots(1)\n",
    "\n",
    "for i, (train_rft, test_rft) in enumerate(cv_rft.split(X,y)):\n",
    "    model_rft = RandomForestClassifier(n_estimators=200, max_features='auto', random_state=42).fit(X[train_rft], y[train_rft])\n",
    "    y_score_rft = model_rft.predict_proba(X[test_rft])\n",
    "    fpr_rft, tpr_rft, _ = roc_curve(y[test_rft], y_score_rft[:, 1])\n",
    "    auc_rft = auc(fpr_rft, tpr_rft)\n",
    "\n",
    "    #plt.plot(fpr_rft, tpr_rft, 'b', alpha=0.15) #label='LR (area = {:.2f})'.format(auc_lr))\n",
    "    plt.plot(fpr_rft, tpr_rft, lw=2, alpha=3, color='aquamarine', label='ROC fold %d (AUC=%f)'%(i,auc_rft))\n",
    "    tpr_rft = interp(base_fpr_rft, fpr_rft, tpr_rft)\n",
    "    tpr_rft[0] = 0.0\n",
    "    tprs_rft.append(tpr_rft)\n",
    "    aucs_rft.append(auc_rft)\n",
    "\n",
    "tprs_rft = np.array(tprs_rft)\n",
    "mean_tprs_rft = tprs_rft.mean(axis=0)\n",
    "std_rft = tprs_rft.std(axis=0)\n",
    "\n",
    "tprs_upper_rft = np.minimum(mean_tprs_rft + std_rft, 1)\n",
    "tprs_lower_rft = mean_tprs_rft - std_rft\n",
    "\n",
    "plt.plot(base_fpr_rft, mean_tprs_rft, 'b')\n",
    "mean_auc_rft = auc(base_fpr_rft, mean_tprs_rft)\n",
    "#print('Auc_rft: ', aucs_rft)\n",
    "#print('mean auc: %f' %mean_auc_rft)\n",
    "\n",
    "#plt.fill_between(base_fpr_rft, tprs_lower_rft, tprs_upper_rft, color='grey', alpha=0.3)\n",
    "plt.plot(base_fpr_rft, mean_tprs_rft, color='turquoise', label=r'Mean ROC (AUC=%f)'%(mean_auc_rft), lw=2, alpha=1)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('RFT ROC Curve')\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "\n",
    "# Hide the right and top spines\n",
    "#ax.spines['right'].set_visible(False)\n",
    "#ax.spines['top'].set_visible(False)\n",
    "# Only show ticks on the left and bottom spines\n",
    "#ax.yaxis.set_ticks_position('left')\n",
    "#ax.xaxis.set_ticks_position('bottom')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cyan & darkcyan\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "cv_svm = KFold(n_splits=10, shuffle=True) # random_state=42\n",
    "\n",
    "tprs_svm = []\n",
    "aucs_svm = []\n",
    "base_fpr_svm = np.linspace(0, 1, 101)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "#fig, ax = plt.subplots(1)\n",
    "\n",
    "for i, (train_svm, test_svm) in enumerate(cv_svm.split(X,y)):\n",
    "    model_svm = SVC(probability=True).fit(X[train_svm], y[train_svm])\n",
    "    y_score_svm = model_svm.predict_proba(X[test_svm])\n",
    "    fpr_svm, tpr_svm, _ = roc_curve(y[test_svm], y_score_svm[:, 1])\n",
    "    auc_svm = auc(fpr_svm, tpr_svm)\n",
    "\n",
    "    #plt.plot(fpr_svm, tpr_svm, 'b', alpha=0.15) #label='LR (area = {:.2f})'.format(auc_lr))\n",
    "    plt.plot(fpr_svm, tpr_svm, lw=2, alpha=3, color='cyan', label='ROC fold %d (AUC=%f)'%(i,auc_svm))\n",
    "    tpr_svm = interp(base_fpr_svm, fpr_svm, tpr_svm)\n",
    "    tpr_svm[0] = 0.0\n",
    "    tprs_svm.append(tpr_svm)\n",
    "    aucs_svm.append(auc_svm)\n",
    "\n",
    "tprs_svm = np.array(tprs_svm)\n",
    "mean_tprs_svm = tprs_svm.mean(axis=0)\n",
    "std_svm = tprs_svm.std(axis=0)\n",
    "\n",
    "tprs_upper_svm = np.minimum(mean_tprs_svm + std_svm, 1)\n",
    "tprs_lower_svm = mean_tprs_svm - std_svm\n",
    "\n",
    "plt.plot(base_fpr_svm, mean_tprs_svm, 'b')\n",
    "mean_auc_svm = auc(base_fpr_svm, mean_tprs_svm)\n",
    "#print('Auc_svm: ', aucs_svm)\n",
    "#print('mean auc: %f' %mean_auc_svm)\n",
    "\n",
    "#plt.fill_between(base_fpr_svm, tprs_lower_svm, tprs_upper_svm, color='grey', alpha=0.3)\n",
    "plt.plot(base_fpr_svm, mean_tprs_svm, color='darkcyan', label=r'Mean ROC (AUC=%f)'%(mean_auc_svm), lw=2, alpha=1)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'b--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('SVM ROC Curve')\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "\n",
    "# Hide the right and top spines\n",
    "#ax.spines['right'].set_visible(False)\n",
    "#ax.spines['top'].set_visible(False)\n",
    "# Only show ticks on the left and bottom spines\n",
    "#ax.yaxis.set_ticks_position('left')\n",
    "#ax.xaxis.set_ticks_position('bottom')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# darkred and red\n",
    "# https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# define k-fold cross validation\n",
    "KF_dnn = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "mean_fpr_dnn = np.linspace(0, 1, 101)\n",
    "tprs_dnn = []\n",
    "aucs_dnn = []\n",
    "for i, (train_dnn, test_dnn) in enumerate(KF_dnn.split(X,y)):\n",
    "    #create model\n",
    "    model_dnn = Sequential()\n",
    "    model_dnn.add(Dense(12, input_dim=12, activation='relu'))\n",
    "    model_dnn.add(Dense(8, activation='relu'))\n",
    "    model_dnn.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    #compile & fit\n",
    "    model_dnn.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    model_dnn.fit(X[train_dnn],y[train_dnn], epochs=100, batch_size=10, verbose=0)\n",
    "                  \n",
    "    # evaluate\n",
    "    y_pred_keras = model_dnn.predict_proba(X[test_dnn]).ravel()\n",
    "    \n",
    "    fpr_dnn, tpr_dnn, thresholds = roc_curve(y[test_dnn], y_pred_keras)              \n",
    "    tprs_dnn.append(interp(mean_fpr_dnn, fpr_dnn,tpr_dnn))\n",
    "    roc_auc_dnn = auc(fpr_dnn,tpr_dnn)\n",
    "    aucs_dnn.append(roc_auc_dnn)   \n",
    "    plt.plot(fpr_dnn, tpr_dnn, lw=2, alpha=3, color='darkred', label='ROC fold %d (AUC=%f)'%(i,roc_auc_dnn))\n",
    "    i = i+1\n",
    "                  \n",
    "plt.plot([0,1], [0,1], linestyle='--', lw=2, color='black')\n",
    "mean_tpr_dnn = np.mean(tprs_dnn, axis=0)\n",
    "mean_auc_dnn = auc(mean_fpr_dnn, mean_tpr_dnn)\n",
    "plt.plot(mean_fpr_dnn, mean_tpr_dnn, color='red', label=r'Mean ROC (AUC=%f)'%(mean_auc_dnn), lw=2, alpha=1)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('DNN ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(1)\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(base_fpr_lr, mean_tprs_lr, color='goldenrod', label=r'LR - Mean ROC (AUC=%f)'%(mean_auc_lr))\n",
    "plt.plot(base_fpr_dt, mean_tprs_dt, color='green', label=r'DT - Mean ROC (AUC=%f)'%(mean_auc_dt))\n",
    "plt.plot(base_fpr_rf, mean_tprs_rf, color='blue', label=r'RF - Mean ROC (AUC=%f)'%(mean_auc_rf))\n",
    "plt.plot(base_fpr_rft, mean_tprs_rft, color='turquoise', label=r'RFT - Mean ROC (AUC=%f)'%(mean_auc_rft))\n",
    "plt.plot(base_fpr_svm, mean_tprs_svm, color='darkcyan', label=r'SVM - Mean ROC (AUC=%f)'%(mean_auc_svm))\n",
    "plt.plot(mean_fpr_dnn, mean_tpr_dnn, color='red', label=r'DNN - Mean ROC (AUC=%f)'%(mean_auc_dnn))\n",
    "\n",
    "plt.xlabel('False Positive Rate/Specificity')\n",
    "plt.ylabel('True Positive Rate/Sensitivity')\n",
    "#plt.title('ROC Curve for All Models')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# hide the right and top spines\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "# \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
